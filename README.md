football_analysis â€“ YOLO-based Football Match Tracker
This project analyzes football videos by detecting and tracking players and the ball using a YOLOv8 model. It produces visual output and saves data for further analytics like tracking positions and movements.

ğŸ“ Folder Structure
bash
Copy
Edit
football_analysis/
â”‚
â”œâ”€â”€ input_videos/              # Raw input videos
â”‚   â””â”€â”€ 15sec_input_720p.mp4
â”‚
â”œâ”€â”€ models/                    # Pre-trained YOLO weights
â”‚   â”œâ”€â”€ best.pt
â”‚   â””â”€â”€ yolo11m.pt
â”‚
â”œâ”€â”€ output_videos/            # Final annotated video output
â”‚   â””â”€â”€ output.avi
â”‚
â”œâ”€â”€ runs/detect/              # YOLO intermediate predictions
â”‚   â””â”€â”€ predict*/15sec_input_720p.avi
â”‚
â”œâ”€â”€ tracker_stubs/
â”‚   â””â”€â”€ player_detection.pkl   # Pickled tracking data
â”‚
â”œâ”€â”€ trackers/                 # Tracker logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ tracker.py
â”‚
â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”œâ”€â”€ bbox_utils.py
â”‚   â””â”€â”€ video_utils.py
â”‚
â”œâ”€â”€ main.py                   # Pipeline entry point
â”œâ”€â”€ yolo_inference.py         # YOLO detection logic
â”œâ”€â”€ yolo11x.pt                # Extra model (if used)
â””â”€â”€ requirements.txt
ğŸš€ Features
âš½ Detects football players and the ball using YOLOv8

ğŸ“ Tracks objects across frames

ğŸ§  Stores tracking data for post-game analysis

ğŸ“¼ Annotated video output with bounding boxes and IDs

ğŸ“¦ Setup Instructions
1. Clone the repository
bash
Copy
Edit
git clone https://github.com/your-username/football_analysis.git
cd football_analysis
2. Create a virtual environment (optional but recommended)
bash
Copy
Edit
python -m venv venv
source venv/bin/activate       # macOS/Linux
# OR
venv\Scripts\activate          # Windows
3. Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
4. Download or add your YOLOv8 model weights
Add your trained best.pt file in the models/ directory.

â–¶ï¸ How to Run
1. Place the input video
Place your .mp4 or .avi match video inside the input_videos/ folder.

2. Run the full pipeline
bash
Copy
Edit
python main.py
This will:

Load the model from models/best.pt

Read the video from input_videos/

Run inference using yolo_inference.py

Store annotated output to output_videos/output.avi

ğŸ–¼ï¸ Sample Output
output_videos/output.avi â€“ includes bounding boxes and labels

runs/detect/ â€“ contains intermediate predictions from YOLO

ğŸ§© Components Explained
File	Description
main.py	Main execution script
yolo_inference.py	Loads model and performs detection
tracker.py	Associates object IDs across frames
bbox_utils.py	Bounding box helper functions
video_utils.py	Video I/O and frame annotation
player_detection.pkl	Pickled object detections

ğŸ“ˆ Model Training (Optional)
If you want to train your own model, you can use the Ultralytics YOLOv8 CLI or script:

bash
Copy
Edit
yolo task=detect mode=train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640
âœ… Requirements
Python â‰¥ 3.8

Ultralytics YOLOv8

OpenCV

NumPy

tqdm

torch, torchvision

Install via:

bash
Copy
Edit
pip install -r requirements.txt
